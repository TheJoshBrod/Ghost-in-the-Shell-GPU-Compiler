Category,ATen Operator,PyTorch API
Core Tensor Ops,aten::add,torch.add / Tensor.add / +
Core Tensor Ops,aten::mul,torch.mul / Tensor.mul / *
Core Tensor Ops,aten::sub,torch.sub / Tensor.sub / -
Core Tensor Ops,aten::div,torch.div / Tensor.div / /
Core Tensor Ops,aten::pow,torch.pow / Tensor.pow / **
Core Tensor Ops,aten::neg,torch.neg / Tensor.neg / -
Core Tensor Ops,aten::abs,torch.abs / Tensor.abs
Core Tensor Ops,aten::exp,torch.exp / Tensor.exp
Core Tensor Ops,aten::log,torch.log / Tensor.log
Core Tensor Ops,aten::sqrt,torch.sqrt / Tensor.sqrt
Core Tensor Ops,aten::rsqrt,torch.rsqrt / Tensor.rsqrt
Core Tensor Ops,aten::reciprocal,torch.reciprocal / Tensor.reciprocal
Core Tensor Ops,aten::round,torch.round / Tensor.round
Core Tensor Ops,aten::floor,torch.floor / Tensor.floor
Core Tensor Ops,aten::ceil,torch.ceil / Tensor.ceil
Core Tensor Ops,aten::clamp,torch.clamp / Tensor.clamp
Core Tensor Ops,aten::maximum,torch.maximum / Tensor.maximum
Core Tensor Ops,aten::minimum,torch.minimum / Tensor.minimum
Core Tensor Ops,aten::where,torch.where
Linear Algebra,aten::mm,torch.mm / Tensor.mm
Linear Algebra,aten::bmm,torch.bmm / Tensor.bmm
Linear Algebra,aten::matmul,torch.matmul / @
Linear Algebra,aten::addmm,torch.addmm / Tensor.addmm
Linear Algebra,aten::einsum,torch.einsum
Linear Algebra,aten::cholesky,torch.linalg.cholesky
Linear Algebra,aten::linalg_svd,torch.linalg.svd
Convolution,aten::conv1d,torch.nn.functional.conv1d / nn.Conv1d
Convolution,aten::conv2d,torch.nn.functional.conv2d / nn.Conv2d
Convolution,aten::conv3d,torch.nn.functional.conv3d / nn.Conv3d
Convolution,aten::conv_transpose2d,torch.nn.functional.conv_transpose2d / nn.ConvTranspose2d
Normalization,aten::batch_norm,torch.nn.functional.batch_norm / nn.BatchNorm2d
Normalization,aten::layer_norm,torch.nn.functional.layer_norm / nn.LayerNorm
Normalization,aten::group_norm,torch.nn.functional.group_norm / nn.GroupNorm
Activation,aten::relu,torch.relu / F.relu / nn.ReLU()
Activation,aten::gelu,torch.nn.functional.gelu / nn.GELU()
Activation,aten::silu,torch.nn.functional.silu / nn.SiLU()
Activation,aten::sigmoid,torch.sigmoid / nn.Sigmoid()
Activation,aten::tanh,torch.tanh / nn.Tanh()
Activation,aten::leaky_relu,torch.nn.functional.leaky_relu / nn.LeakyReLU()
Activation,aten::softmax,torch.nn.functional.softmax / nn.Softmax()
Pooling,aten::max_pool2d,torch.nn.functional.max_pool2d / nn.MaxPool2d()
Pooling,aten::avg_pool2d,torch.nn.functional.avg_pool2d / nn.AvgPool2d()
Pooling,aten::adaptive_avg_pool2d,torch.nn.functional.adaptive_avg_pool2d / nn.AdaptiveAvgPool2d()
Reduction,aten::mean,torch.mean / Tensor.mean
Reduction,aten::sum,torch.sum / Tensor.sum
Reduction,aten::std,torch.std / Tensor.std
Reduction,aten::var,torch.var / Tensor.var
Reduction,aten::norm,torch.norm / Tensor.norm
Tensor Creation,aten::empty,torch.empty
Tensor Creation,aten::zeros,torch.zeros
Tensor Creation,aten::ones,torch.ones
Tensor Creation,aten::full,torch.full
Tensor Creation,aten::rand,torch.rand
Tensor Creation,aten::randn,torch.randn
Tensor Creation,aten::arange,torch.arange
Tensor Creation,aten::linspace,torch.linspace
Tensor Creation,aten::eye,torch.eye
Tensor Reshape,aten::view,Tensor.view
Tensor Reshape,aten::reshape,torch.reshape / Tensor.reshape
Tensor Reshape,aten::flatten,torch.flatten / Tensor.flatten
Tensor Reshape,aten::squeeze,torch.squeeze / Tensor.squeeze
Tensor Reshape,aten::unsqueeze,torch.unsqueeze / Tensor.unsqueeze
Tensor Reshape,aten::permute,Tensor.permute
Tensor Reshape,aten::transpose,torch.transpose / Tensor.transpose
Tensor Reshape,aten::cat,torch.cat
Tensor Reshape,aten::stack,torch.stack
Tensor Indexing,aten::gather,torch.gather / Tensor.gather
Tensor Indexing,aten::scatter,torch.scatter / Tensor.scatter_
Random,aten::bernoulli,torch.bernoulli
Random,aten::normal,torch.normal
Random,aten::uniform,torch.uniform
Random,aten::rand_like,torch.rand_like
Random,aten::randn_like,torch.randn_like
Loss,aten::nll_loss,torch.nn.functional.nll_loss / nn.NLLLoss
Loss,aten::cross_entropy_loss,torch.nn.functional.cross_entropy / nn.CrossEntropyLoss
Loss,aten::mse_loss,torch.nn.functional.mse_loss / nn.MSELoss
Loss,aten::smooth_l1_loss,torch.nn.functional.smooth_l1_loss / nn.SmoothL1Loss
Loss,aten::binary_cross_entropy,torch.nn.functional.binary_cross_entropy / nn.BCELoss
Loss,aten::binary_cross_entropy_with_logits,torch.nn.functional.binary_cross_entropy_with_logits / nn.BCEWithLogitsLoss
Transformer,aten::scaled_dot_product_attention,torch.nn.functional.scaled_dot_product_attention
Transformer,aten::_scaled_dot_product_flash_attention,torch.backends.cuda.flash_attention (internal)
Utility,aten::detach,Tensor.detach
Utility,aten::requires_grad_,Tensor.requires_grad_
Utility,aten::contiguous,Tensor.contiguous
Utility,aten::item,Tensor.item
Utility,aten::numel,Tensor.numel
Utility,aten::size,Tensor.size
Utility,aten::stride,Tensor.stride
Utility,aten::select,Tensor.select
