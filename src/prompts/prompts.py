aten_to_cuda = """
Your task is to translate high-level operator descriptions into functional CUDA kernel code.

You will receive text containing:
- "Aggregated Operator Performance" (e.g., aten::mm, aten::sin) 
- "Detailed CUDA Kernel Breakdown" (e.g. volta_sgemm_128x64_nn, void at::native::vectorized_elementwise_kernel<4, at::native::sin_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, std::array<char*, 2ul> >(int, at::native::sin_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, std::array<char*, 2ul>))

Based on this information, write the corresponding CUDA __global__ kernel functions.

Critically Important Rules:

Your response MUST contain ONLY the raw CUDA C++ code.

Do NOT include any explanations, introductory text, main functions, #include statements, or markdown formatting.

For matrix multiplication such as aten::mm, provide a standard, non-tiled implementation.

For element-wise operations such as aten::sin, provide a standard grid-stride loop implementation.
"""


aten_to_cuda_fixer = """
Your task is to fix a CUDA kernel code given an existing flawed CUDA kernel, correct high-level operator descriptions of original PyTorch, Error Message of why the CUDA broke.


High Level Operator will be formatted something like:
- "Aggregated Operator Performance" (e.g., aten::mm, aten::sin) 
- "Detailed CUDA Kernel Breakdown" (e.g. volta_sgemm_128x64_nn, void at::native::vectorized_elementwise_kernel<4, at::native::sin_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, std::array<char*, 2ul> >(int, at::native::sin_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, std::array<char*, 2ul>))

Based on this information, write an updated CUDA __global__ kernel function.

Critically Important Rules:

Your response MUST contain ONLY the raw CUDA C++ code.

Do NOT include any explanations, introductory text, main functions, #include statements, or markdown formatting.

For matrix multiplication such as aten::mm, provide a standard, non-tiled implementation.

For element-wise operations such as aten::sin, provide a standard grid-stride loop implementation.
"""

def get_generation_sys_prompt(outputIR: str) -> str:
    """Retrieves System Prompt for generating initial kernels.

    Args:
        outputIR (str): Desired IR/Kernel to be generated by LLM

    Returns:
        str: System prompt for the IR/Kernel
    """

    if outputIR == "CUDA":
        return aten_to_cuda
    else:
        return ""

def get_fixer_sys_prompt(outputIR: str) -> str:
    """Retrieves System Prompt for fixing broken kernels.

    Args:
        outputIR (str): Desired IR/Kernel to be generated by LLM

    Returns:
        str: System prompt for the IR/Kernel
    """

    if outputIR == "CUDA":
        return aten_to_cuda_fixer
    else:
        return ""

def generate_fixer_prompt(kernel: str, error: str, msg: str,) -> str:
    """Generates a prompt used for an LLM to fix an existing kernels.

    Args:
        kernel (str): Previous version of the malformed/incorrect Kernel generated
        error (str): Custom error message to inform what the LLM did wrong 
        msg (str): Context the ORIGINAL LLM had to generate Kernel/IR

    Returns:
        str: Merged prompt for the LLM to fix the Kernel/IR
    """
    
    prompt = f"""
    [BROKEN KERNEL]
    {kernel}

    [ERROR/REASON IT NEEDS FIXING]
    {error}

    [ORIGINAL CONTEXT]
    {msg}
    """

    return prompt